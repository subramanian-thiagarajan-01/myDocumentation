<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="turbo-cache-control" content="no-cache" data-turbo-track="reload" data-track-token="3.11.0.820258908846">

    <!-- See retype.com -->
    <meta name="generator" content="Retype 3.11.0">

    <!-- Primary Meta Tags -->
    <title>19. PySpark &amp; SQL Common Interview Scenarios &#129514;</title>
    <meta name="title" content="19. PySpark & SQL Common Interview Scenarios üß™">
    <meta name="description" content="Problem: Build an ETL pipeline that:">

    <!-- Canonical -->
    <link rel="canonical" href="https://subramanian-thiagarajan-01.github.io/spark/19-pyspark-sql-common-interview-scenarios/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://subramanian-thiagarajan-01.github.io/spark/19-pyspark-sql-common-interview-scenarios/">
    <meta property="og:title" content="19. PySpark & SQL Common Interview Scenarios üß™">
    <meta property="og:description" content="Problem: Build an ETL pipeline that:">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://subramanian-thiagarajan-01.github.io/spark/19-pyspark-sql-common-interview-scenarios/">
    <meta property="twitter:title" content="19. PySpark & SQL Common Interview Scenarios üß™">
    <meta property="twitter:description" content="Problem: Build an ETL pipeline that:">

    <script data-cfasync="false">(function(){var cl=document.documentElement.classList,ls=localStorage.getItem("retype_scheme"),hd=cl.contains("dark"),hl=cl.contains("light"),wm=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;if(ls==="dark"||(!ls&&wm&&!hd&&!hl)){cl.remove("light");cl.add("dark")}else if(ls==="light"||(!ls&&!wm&&!hd&&!hl)){cl.remove("dark");cl.add("light")}})();</script>

    <link href="../../resources/css/retype.css?v=3.11.0.820258908846" rel="stylesheet">

    <script data-cfasync="false" src="../../resources/js/config.js?v=3.11.0.820258908846" data-turbo-eval="false" defer></script>
    <script data-cfasync="false" src="../../resources/js/retype.js?v=3.11.0" data-turbo-eval="false" defer></script>
    <script id="lunr-js" data-cfasync="false" src="../../resources/js/lunr.js?v=3.11.0.820258908846" data-turbo-eval="false" defer></script>
    <script id="prism-js" data-cfasync="false" src="../../resources/js/prism.js?v=3.11.0.820258908846" defer></script>
</head>
<body>
    <div id="retype-app" class="relative text-base antialiased text-base-text bg-base-bg font-body">
        <div class="absolute bottom-0 left-0" style="top: 5rem; right: 50%"></div>
    
        <header id="retype-header" class="sticky top-0 z-30 flex w-full h-16 bg-header-bg border-b border-header-border md:h-20">
            <div class="container relative flex items-center justify-between pr-6 grow md:justify-start">
                <!-- Mobile menu button skeleton -->
                <button v-cloak class="skeleton retype-mobile-menu-button flex items-center justify-center shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
                <div v-cloak id="retype-sidebar-left-toggle-button"></div>
        
                <!-- Logo -->
                <div class="flex items-center justify-between h-full py-2 md:w-75">
                    <div class="flex items-center px-2 md:px-6">
                        <a id="retype-branding-logo" href="../../" class="flex items-center leading-snug text-xl">
                            <span class="dark:text-white font-bold line-clamp-1 md:line-clamp-2">My Documentation</span>
                        </a><span id="retype-branding-label" class="inline-flex mt-1 px-2 py-1 ml-4 text-xs font-medium leading-none items-center rounded-md bg-branding-label-bg text-branding-label-text ring-1 ring-branding-label-border ring-inset md:inline-block">Docs</span>
                    </div>
        
                    <span class="hidden h-8 border-r md:inline-block border-base-border"></span>
                </div>
        
                <div class="flex justify-between md:grow">
                    <!-- Top Nav -->
                    <nav id="retype-header-nav" class="hidden md:flex">
                        <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
                            
                        </ul>
                    </nav>
        
                    <!-- Header Right Skeleton -->
                    <div v-cloak class="flex justify-end grow skeleton">
        
                        <!-- Search input mock -->
                        <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                            <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                                <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                            </div>
                            <input class="w-full h-10 placeholder-search-placeholder transition-colors duration-200 ease-in bg-search-bg border border-transparent rounded md:text-sm hover:border-search-border-hover focus:outline-none focus:border-search-border-focus" style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search">
                        </div>
        
                        <!-- Mobile search button -->
                        <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                        </div>
        
                        <!-- Dark mode switch placeholder -->
                        <div class="w-10 h-10 lg:ml-2"></div>
        
                        <!-- History button -->
                        <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                        </div>
                    </div>
        
                    <div v-cloak class="flex justify-end grow">
                        <div id="retype-mobile-search-button"></div>
                        <doc-search-desktop></doc-search-desktop>
        
                        <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                        <doc-history></doc-history>
                    </div>
                </div>
            </div>
        </header>
    
    
        <div id="retype-container" class="container relative flex bg-white">
            <!-- Sidebar Skeleton -->
            <div v-cloak class="fixed flex flex-col shrink-0 duration-300 ease-in-out bg-sidebar-left-bg border-sidebar-left-border sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton">
            
                <div class="flex items-center h-16 px-6">
                    <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-filter-bg border border-filter-border rounded shadow-none text-sm focus:outline-none focus:border-filter-border-focus" type="text" placeholder="Filter">
                </div>
            
                <div class="pl-6 mt-1 mb-4">
                    <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                </div>
            
                <div class="shrink-0 mt-auto bg-transparent dark:border-base-border">
                    <a class="flex items-center justify-center flex-nowrap h-16 text-gray-350 dark:text-dark-400 hover:text-gray-600 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                        <span class="text-xs whitespace-nowrap">Powered by</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                    </a>
                </div>
            </div>
            
            <!-- Sidebar component -->
            <doc-sidebar v-cloak>
                <template #sidebar-footer>
                    <div class="shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-base-border">
            
                        <a class="flex items-center justify-center flex-nowrap h-16 text-gray-350 dark:text-dark-400 hover:text-gray-600 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                            <span class="text-xs whitespace-nowrap">Powered by</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                        </a>
                    </div>
                </template>
            </doc-sidebar>
    
            <div class="grow min-w-0 bg-body-bg">
                <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
                <div class="flex">
                    <div id="retype-main" class="min-w-0 p-4 grow md:px-16">
                        <main class="relative pb-12 lg:pt-2">
                            <div class="retype-markdown" id="retype-content">
                                <!-- Rendered if sidebar right is enabled -->
                                <div id="retype-sidebar-right-toggle"></div>
                                <!-- Page content  -->
<doc-anchor-target id="19-pyspark--sql-common-interview-scenarios-" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#19-pyspark--sql-common-interview-scenarios-">#</doc-anchor-trigger>
        <span>19. PySpark &amp; SQL Common Interview Scenarios <span class="docs-emoji">&#x1F9EA;</span></span>
    </h1>
</doc-anchor-target>
<doc-anchor-target id="scenario-1-etl-pipeline-in-spark">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-1-etl-pipeline-in-spark">#</doc-anchor-trigger>
        <span>Scenario 1: ETL Pipeline in Spark</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Build an ETL pipeline that:</p>
<ol>
<li>Reads raw sales data from CSV</li>
<li>Cleans and transforms data</li>
<li>Joins with product information</li>
<li>Aggregates by category</li>
<li>Writes to Parquet</li>
</ol>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python">from pyspark.sql import SparkSession
from pyspark.sql.functions import *

spark = SparkSession.builder \
    .appName(&quot;ETL_Pipeline&quot;) \
    .config(&quot;spark.sql.shuffle.partitions&quot;, &quot;200&quot;) \
    .getOrCreate()

# Read raw data
sales = spark.read \
    .option(&quot;header&quot;, &quot;true&quot;) \
    .option(&quot;inferSchema&quot;, &quot;true&quot;) \
    .csv(&quot;s3://raw-data/sales.csv&quot;)

products = spark.read.parquet(&quot;s3://reference/products.parquet&quot;)

# Clean: Remove nulls, invalid amounts
sales_clean = sales \
    .dropna(subset=[&quot;order_id&quot;, &quot;product_id&quot;, &quot;amount&quot;]) \
    .filter(col(&quot;amount&quot;) &gt; 0) \
    .withColumn(&quot;amount&quot;, col(&quot;amount&quot;).cast(&quot;double&quot;))

# Transform: Add calculated columns
sales_transform = sales_clean \
    .withColumn(&quot;tax&quot;, col(&quot;amount&quot;) * 0.1) \
    .withColumn(&quot;net_amount&quot;, col(&quot;amount&quot;) - col(&quot;tax&quot;)) \
    .withColumn(&quot;date_key&quot;, date_format(col(&quot;order_date&quot;), &quot;yyyyMMdd&quot;))

# Join with products
joined = sales_transform.join(
    products,
    sales_transform.product_id == products.id,
    &quot;left&quot;
)

# Aggregate
result = joined.groupBy(&quot;category&quot;, &quot;date_key&quot;) \
    .agg(
        count(&quot;*&quot;).alias(&quot;order_count&quot;),
        sum(&quot;net_amount&quot;).alias(&quot;total_sales&quot;),
        avg(&quot;net_amount&quot;).alias(&quot;avg_order_value&quot;),
        max(&quot;amount&quot;).alias(&quot;max_order&quot;)
    )

# Write to Parquet (partitioned by date)
result.write \
    .mode(&quot;overwrite&quot;) \
    .partitionBy(&quot;date_key&quot;) \
    .parquet(&quot;s3://processed-data/sales_summary/&quot;)

# Verify
spark.read.parquet(&quot;s3://processed-data/sales_summary/&quot;).show()</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-2-incremental-load-cdc">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-2-incremental-load-cdc">#</doc-anchor-trigger>
        <span>Scenario 2: Incremental Load (CDC)</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Load only new/changed records since last load.</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python"># Last load timestamp
last_load_time = spark.sql(&quot;SELECT MAX(modified_at) FROM delta_table&quot;).collect()[0][0]

# Read new data
new_data = spark.read.csv(&quot;s3://source/&quot;) \
    .filter(col(&quot;modified_at&quot;) &gt; last_load_time)

# Merge into target
from delta.tables import DeltaTable

target = DeltaTable.forPath(spark, &quot;s3://target/delta_table/&quot;)

target.alias(&quot;t&quot;).merge(
    new_data.alias(&quot;s&quot;),
    &quot;t.id = s.id&quot;
).whenMatchedUpdateAll() \
.whenNotMatchedInsertAll() \
.execute()

# Track load time
spark.sql(&quot;&quot;&quot;
    INSERT INTO load_metadata (last_load_time, record_count)
    VALUES (current_timestamp(), {})
&quot;&quot;&quot;.format(new_data.count()))</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-3-scd-type-2-implementation">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-3-scd-type-2-implementation">#</doc-anchor-trigger>
        <span>Scenario 3: SCD Type 2 Implementation</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Maintain historical changes in a dimension table.</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python"># New dimension data
new_data = spark.createDataFrame([
    (1, &quot;Alice&quot;, &quot;NYC&quot;, &quot;2024-06-01&quot;),
    (2, &quot;Bob&quot;, &quot;Seattle&quot;, &quot;2024-06-01&quot;),
    (3, &quot;Charlie&quot;, &quot;LA&quot;, &quot;2024-06-01&quot;)
], [&quot;cust_id&quot;, &quot;name&quot;, &quot;city&quot;, &quot;effective_date&quot;])

# Load current dimension
current = spark.read.parquet(&quot;s3://dimension/customer/&quot;)

# Find changed records
changed = new_data.alias(&quot;new&quot;) \
    .join(
        current.alias(&quot;current&quot;),
        new_data.cust_id == current.cust_id,
        &quot;left&quot;
    ) \
    .filter(
        (col(&quot;current.cust_id&quot;).isNull()) | \
        (col(&quot;new.city&quot;) != col(&quot;current.city&quot;))
    )

# Update old records (set end_date)
to_close = current \
    .join(
        changed.select(&quot;cust_id&quot;),
        &quot;cust_id&quot;,
        &quot;inner&quot;
    ) \
    .withColumn(&quot;end_date&quot;, lit(date_sub(current_date(), 1))) \
    .withColumn(&quot;is_current&quot;, lit(False))

# New records (no end_date)
to_add = new_data.select(
    &quot;cust_id&quot;, &quot;name&quot;, &quot;city&quot;,
    col(&quot;effective_date&quot;).alias(&quot;start_date&quot;),
    lit(None).alias(&quot;end_date&quot;),
    lit(True).alias(&quot;is_current&quot;)
)

# Keep unchanged current records
unchanged = current \
    .join(
        changed.select(&quot;cust_id&quot;),
        &quot;cust_id&quot;,
        &quot;anti&quot;
    )

# Union all
result = to_close.union(to_add).union(unchanged)

# Write
result.write.mode(&quot;overwrite&quot;).parquet(&quot;s3://dimension/customer_scd2/&quot;)</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-4-handling-skew">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-4-handling-skew">#</doc-anchor-trigger>
        <span>Scenario 4: Handling Skew</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Some keys have disproportionately more data (skew).</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python"># Detect skew
skew_analysis = df.groupBy(&quot;customer_id&quot;).count() \
    .orderBy(desc(&quot;count&quot;))

skew_analysis.show()  # See data distribution

# Mitigation 1: Broadcast join (if small table)
df_large.join(broadcast(df_small), &quot;id&quot;)

# Mitigation 2: Salting (add random suffix to high-volume keys)
df_salted = df.withColumn(
    &quot;salt&quot;,
    when(
        col(&quot;customer_id&quot;).isin([highly_skewed_ids]),
        (rand() * 10).cast(&quot;int&quot;)
    ).otherwise(0)
)

df_salted = df_salted.withColumn(
    &quot;salted_key&quot;,
    concat(col(&quot;customer_id&quot;), col(&quot;salt&quot;))
)

# Join on salted key
result = df_salted.join(other, &quot;salted_key&quot;)

# Remove salt from result
result = result.withColumn(&quot;customer_id&quot;, regexp_replace(&quot;customer_id&quot;, &quot;_\\d+&quot;, &quot;&quot;))

# Mitigation 3: Repartition to spread skew
df.repartition(500, &quot;customer_id&quot;)</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-5-large-file-processing">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-5-large-file-processing">#</doc-anchor-trigger>
        <span>Scenario 5: Large File Processing</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Process 100GB+ file efficiently.</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python"># Read with optimal settings
df = spark.read \
    .parquet(&quot;s3://large_file/&quot;) \
    .repartition(500)  # Ensure enough parallelism

# Filter early (predicate pushdown)
df_filtered = df.filter(col(&quot;amount&quot;) &gt; 0)

# Use columnar operations (no UDFs)
result = df_filtered.groupBy(&quot;category&quot;) \
    .agg(
        sum(&quot;amount&quot;).alias(&quot;total&quot;),
        count(&quot;*&quot;).alias(&quot;count&quot;),
        avg(&quot;amount&quot;).alias(&quot;avg_amount&quot;)
    )

# Repartition for output (optimal for writing)
result.coalesce(100).write \
    .mode(&quot;overwrite&quot;) \
    .partitionBy(&quot;category&quot;) \
    .parquet(&quot;s3://output/&quot;)

# Monitor via Spark UI
# - Check shuffle read/write sizes
# - Ensure no severe skew
# - Monitor executor memory</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-6-complex-window-function">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-6-complex-window-function">#</doc-anchor-trigger>
        <span>Scenario 6: Complex Window Function</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Rank products by sales within category, keep top 3, calculate rank% of category total.</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python">from pyspark.sql.window import Window

sales = spark.read.parquet(&quot;sales.parquet&quot;)

window_rank = Window.partitionBy(&quot;category&quot;) \
    .orderBy(col(&quot;total_sales&quot;).desc())

window_partition = Window.partitionBy(&quot;category&quot;)

result = sales.withColumn(
    &quot;sales_rank&quot;,
    rank().over(window_rank)
).withColumn(
    &quot;category_total&quot;,
    sum(&quot;total_sales&quot;).over(window_partition)
).withColumn(
    &quot;sales_pct&quot;,
    (col(&quot;total_sales&quot;) / col(&quot;category_total&quot;) * 100).cast(&quot;decimal(5,2)&quot;)
).filter(
    col(&quot;sales_rank&quot;) &lt;= 3
).select(
    &quot;category&quot;, &quot;product&quot;, &quot;total_sales&quot;, &quot;sales_rank&quot;, &quot;sales_pct&quot;
)

result.show()</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-7-data-quality-checks">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-7-data-quality-checks">#</doc-anchor-trigger>
        <span>Scenario 7: Data Quality Checks</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Validate data before processing.</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python"># Quality checks
checks = {
    &quot;null_orders&quot;: df.filter(col(&quot;order_id&quot;).isNull()).count(),
    &quot;null_amounts&quot;: df.filter(col(&quot;amount&quot;).isNull()).count(),
    &quot;negative_amounts&quot;: df.filter(col(&quot;amount&quot;) &lt; 0).count(),
    &quot;duplicate_orders&quot;: df.groupBy(&quot;order_id&quot;).count().filter(col(&quot;count&quot;) &gt; 1).count(),
    &quot;future_dates&quot;: df.filter(col(&quot;order_date&quot;) &gt; current_date()).count()
}

# Report
for check, count in checks.items():
    status = &quot;‚úì PASS&quot; if count == 0 else f&quot;‚úó FAIL ({count})&quot;
    print(f&quot;{check}: {status}&quot;)

# Fail pipeline if critical checks fail
assert checks[&quot;null_orders&quot;] == 0, &quot;Found null order IDs&quot;
assert checks[&quot;negative_amounts&quot;] == 0, &quot;Found negative amounts&quot;

# Log to table
quality_log = spark.createDataFrame([
    (current_timestamp(), check, count)
    for check, count in checks.items()
], [&quot;timestamp&quot;, &quot;check_name&quot;, &quot;failed_count&quot;])

quality_log.write.mode(&quot;append&quot;).parquet(&quot;s3://quality_logs/&quot;)</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="scenario-8-optimized-join">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#scenario-8-optimized-join">#</doc-anchor-trigger>
        <span>Scenario 8: Optimized Join</span>
    </h2>
</doc-anchor-target>
<p><strong>Problem</strong>: Join 10GB table with 5GB table efficiently.</p>
<p><strong>Solution</strong>:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-python"><code v-pre class="language-python"># Read both tables
large = spark.read.parquet(&quot;large.parquet&quot;)
medium = spark.read.parquet(&quot;medium.parquet&quot;)

# Pre-filter to reduce data
large_filtered = large.filter(col(&quot;status&quot;) == &quot;active&quot;)
medium_filtered = medium.filter(col(&quot;valid&quot;) == True)

# Pre-repartition both by join key
large_repartitioned = large_filtered.repartition(100, &quot;id&quot;)
medium_repartitioned = medium_filtered.repartition(100, &quot;id&quot;)

# Sort both (prepares for sort-merge join)
large_sorted = large_repartitioned.sortByKey()
medium_sorted = medium_repartitioned.sortByKey()

# Join (no shuffle, leverages pre-sorting)
result = large_sorted.join(medium_sorted, &quot;id&quot;)

# Aggregate
final = result.groupBy(&quot;category&quot;) \
    .agg(sum(&quot;amount&quot;).alias(&quot;total&quot;))

# Write
final.write.parquet(&quot;s3://output/&quot;)</code></pre>
</doc-codeblock></div>
<hr>
<doc-anchor-target id="conclusion">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#conclusion">#</doc-anchor-trigger>
        <span>Conclusion</span>
    </h2>
</doc-anchor-target>
<p>This comprehensive guide covers:</p>
<ol>
<li><strong>Architecture</strong>: Driver, executors, cluster managers, memory, schedulers</li>
<li><strong>Core Abstractions</strong>: RDD, DataFrame, Dataset differences</li>
<li><strong>Optimization</strong>: Catalyst, Tungsten, code generation</li>
<li><strong>Operations</strong>: Transformations, actions, lazy evaluation</li>
<li><strong>Performance</strong>: Partitioning, shuffling, joins, broadcasting</li>
<li><strong>Analytics</strong>: Window functions, aggregations, deduplication</li>
<li><strong>Advanced</strong>: UDF, Pandas UDF, caching, checkpointing</li>
<li><strong>Streaming</strong>: Structured Streaming, watermarking, joins</li>
<li><strong>Storage</strong>: Parquet, ORC, Delta, CSV, JSON</li>
<li><strong>Real-World Scenarios</strong>: ETL, CDC, SCD Type 2, skew handling, data quality</li>
</ol>
<p>Master these concepts to become a strong Spark engineer capable of building scalable, performant data pipelines.</p>

                                
                                <!-- Required only on API pages -->
                                <doc-toolbar-member-filter-no-results></doc-toolbar-member-filter-no-results>
                            </div>
                            <footer id="retype-content-footer" class="clear-both">
                            
                                <nav id="retype-nextprev" class="print:hidden flex mt-14">
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 h-full flex items-center break-normal font-medium text-body-link border border-base-border hover:border-base-border-hover rounded-l-lg transition-colors duration-150 relative hover:z-5" href="../../spark/18-delta-lake-integration/">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                            <span>
                                                <span class="block text-xs font-normal text-base-text-muted">Previous</span>
                                                <span class="block mt-1">18. Delta Lake Integration üè∑Ô∏è</span>
                                            </span>
                                        </a>
                                    </div>
                            
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-normal font-medium text-body-link border border-base-border hover:border-base-border-hover rounded-r-lg transition-colors duration-150 relative hover:z-5" href="../../spark-declarative-pipelines/introduction/">
                                            <span>
                                                <span class="block text-xs font-normal text-right text-base-text-muted">Next</span>
                                                <span class="block mt-1">1. Introduction</span>
                                            </span>
                                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                        </a>
                                    </div>
                                </nav>
                            </footer>
                        </main>
                
                        <div id="retype-page-footer" class="print:border-none border-t border-base-border pt-6 mb-8">
                            <footer class="flex flex-wrap items-center justify-between print:justify-center">
                                <div id="retype-footer-links" class="print:hidden">
                                    <ul class="flex flex-wrap items-center text-sm">
                                    </ul>
                                </div>
                                <div id="retype-copyright" class="print:justify-center py-2 text-footer-text font-footer-link-weight text-sm leading-relaxed"></div>
                            </footer>
                        </div>
                    </div>
                
                    <!-- Rendered if sidebar right is enabled -->
                    <!-- Sidebar right skeleton-->
                    <div v-cloak class="fixed top-0 bottom-0 right-0 translate-x-full bg-sidebar-right-bg border-sidebar-right-border lg:sticky lg:border-l lg:shrink-0 lg:pt-6 lg:transform-none sm:w-1/2 lg:w-64 lg:z-0 md:w-104 sidebar-right skeleton">
                        <div class="pl-5">
                            <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                            <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                            <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                        </div>
                    </div>
                
                    <!-- User should be able to hide sidebar right -->
                    <doc-sidebar-right v-cloak></doc-sidebar-right>
                </div>

            </div>
        </div>
    
        <doc-search-mobile></doc-search-mobile>
        <doc-back-to-top></doc-back-to-top>
    </div>


    <div id="retype-overlay-target"></div>

    <script data-cfasync="false">window.__DOCS__ = { "title": "19. PySpark & SQL Common Interview Scenarios üß™", level: 2, icon: "file", hasPrism: true, hasMermaid: false, hasMath: false, tocDepth: 23 }</script>
</body>
</html>
