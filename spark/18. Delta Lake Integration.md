# 18. Delta Lake Integration üè∑Ô∏è

**Delta Lake** brings ACID properties and time travel to Spark.

```python
# Write to Delta
df.write \
    .format("delta") \
    .mode("overwrite") \
    .save("s3://bucket/delta_table/")

# Read from Delta
df = spark.read.format("delta").load("s3://bucket/delta_table/")

# MERGE operation (UPSERT)
from delta.tables import DeltaTable

delta_table = DeltaTable.forPath(spark, "s3://bucket/delta_table/")

delta_table.alias("target").merge(
    source_df.alias("source"),
    "target.id = source.id"
).whenMatchedUpdate(
    set={"amount": col("source.amount")}
).whenNotMatchedInsert(
    values={"id": col("source.id"), "amount": col("source.amount")}
).execute()

# Time travel
df_v1 = spark.read \
    .format("delta") \
    .option("versionAsOf", 1) \
    .load("s3://bucket/delta_table/")

df_past = spark.read \
    .format("delta") \
    .option("timestampAsOf", "2024-01-01") \
    .load("s3://bucket/delta_table/")

# Get table history
spark.sql("SELECT * FROM delta.`s3://bucket/delta_table/`/_delta_log")
```
